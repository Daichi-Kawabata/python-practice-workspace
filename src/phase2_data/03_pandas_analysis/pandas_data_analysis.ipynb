{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704eb7e0",
   "metadata": {},
   "source": [
    "# pandas基礎：データ操作・分析入門\n",
    "\n",
    "このノートブックでは、**pandas**を使った基本的なデータ操作と分析手法を学習します。\n",
    "\n",
    "## 学習内容\n",
    "1. pandasの基本設定とインポート\n",
    "2. サンプルデータの作成とDataFrame生成\n",
    "3. CSVファイルからのデータ読み込み\n",
    "4. データの基本情報確認\n",
    "5. 列・行の抽出とフィルタリング\n",
    "6. データの集計（groupby）\n",
    "7. データの並び替えと欠損値処理\n",
    "8. 簡単なグラフ描画\n",
    "\n",
    "## 前提知識\n",
    "- Python基礎文法\n",
    "- リスト、辞書などの基本データ構造"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a73900",
   "metadata": {},
   "source": [
    "## 1. pandasのインポートと基本設定\n",
    "\n",
    "必要なライブラリをインポートし、pandasの表示設定を調整します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d736553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "# 表示設定\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Matplotlib日本語フォント設定（警告を抑制）\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Seabornスタイル設定\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"必要なライブラリがインポートされました！\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796568a",
   "metadata": {},
   "source": [
    "## 2. サンプルデータの作成とDataFrame生成\n",
    "\n",
    "pandasのDataFrameを作成する方法を学習します。辞書やリストから直接DataFrameを作成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37bb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書からDataFrameを作成\n",
    "students_data = {\n",
    "    '名前': ['田中太郎', '佐藤花子', '鈴木一郎', '高橋美咲', '山田次郎'],\n",
    "    '年齢': [20, 19, 21, 20, 22],\n",
    "    '学部': ['工学部', '文学部', '理学部', '経済学部', '法学部'],\n",
    "    '数学': [85, 92, 78, 90, 88],\n",
    "    '英語': [78, 88, 85, 92, 75],\n",
    "    '国語': [90, 85, 88, 87, 92]\n",
    "}\n",
    "\n",
    "# DataFrameの作成\n",
    "df_students = pd.DataFrame(students_data)\n",
    "\n",
    "print(\"学生データのDataFrame:\")\n",
    "print(df_students)\n",
    "print(f\"\\nDataFrameの形状: {df_students.shape}\")  # (行数, 列数)\n",
    "print(f\"データ型:\\n{df_students.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# より複雑なサンプルデータの作成（売上データ）\n",
    "np.random.seed(42)  # 再現性のため\n",
    "\n",
    "# 日付データの生成\n",
    "start_date = datetime(2024, 1, 1)\n",
    "dates = [start_date + timedelta(days=i) for i in range(30)]\n",
    "\n",
    "# ランダムデータの生成\n",
    "sales_data = {\n",
    "    '日付': np.random.choice(dates, 100),\n",
    "    '商品名': np.random.choice(['商品A', '商品B', '商品C', '商品D', '商品E'], 100),\n",
    "    'カテゴリ': np.random.choice(['電子機器', '衣料品', '食品', '書籍'], 100),\n",
    "    '単価': np.random.randint(100, 1000, 100),\n",
    "    '数量': np.random.randint(1, 10, 100),\n",
    "    '地域': np.random.choice(['東京', '大阪', '名古屋', '福岡'], 100)\n",
    "}\n",
    "\n",
    "# DataFrameの作成\n",
    "df_sales = pd.DataFrame(sales_data)\n",
    "\n",
    "# 売上金額の計算（新しい列を追加）\n",
    "df_sales['売上金額'] = df_sales['単価'] * df_sales['数量']\n",
    "\n",
    "print(\"売上データのDataFrame（最初の10行）:\")\n",
    "print(df_sales.head(10))\n",
    "print(f\"\\nDataFrameの形状: {df_sales.shape}\")\n",
    "\n",
    "# CSVファイルに保存（後で使用）\n",
    "df_sales.to_csv('sample_sales_data.csv', index=False, encoding='utf-8')\n",
    "print(\"\\nデータを 'sample_sales_data.csv' に保存しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe16c5",
   "metadata": {},
   "source": [
    "## 3. データの読み込み（CSVファイル）\n",
    "\n",
    "pandasの`read_csv()`関数を使って、CSVファイルからデータを読み込む方法を学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVファイルからデータを読み込み\n",
    "try:\n",
    "    df_loaded = pd.read_csv('sample_sales_data.csv', encoding='utf-8')\n",
    "    print(\"CSVファイルからデータを読み込みました\")\n",
    "    print(f\"読み込んだデータの形状: {df_loaded.shape}\")\n",
    "    print(\"\\n最初の5行:\")\n",
    "    print(df_loaded.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"CSVファイルが見つかりません。先にサンプルデータを作成してください。\")\n",
    "    df_loaded = df_sales  # 代替として先ほど作成したデータを使用\n",
    "\n",
    "# 日付列をdatetime型に変換\n",
    "df_loaded['日付'] = pd.to_datetime(df_loaded['日付'])\n",
    "\n",
    "print(f\"\\n日付列のデータ型: {df_loaded['日付'].dtype}\")\n",
    "print(f\"データ型一覧:\\n{df_loaded.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba8abe",
   "metadata": {},
   "source": [
    "## 4. データの基本情報確認\n",
    "\n",
    "`shape`, `head()`, `info()`, `describe()`などを使って、データの基本的な情報を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの基本情報確認\n",
    "print(\"=== データの基本情報 ===\")\n",
    "\n",
    "# 1. データの形状\n",
    "print(f\"1. データの形状: {df_loaded.shape}\")\n",
    "print(f\"   行数: {df_loaded.shape[0]}, 列数: {df_loaded.shape[1]}\")\n",
    "\n",
    "# 2. 列名の確認\n",
    "print(f\"\\n2. 列名: {list(df_loaded.columns)}\")\n",
    "\n",
    "# 3. 最初の数行\n",
    "print(\"\\n3. 最初の5行:\")\n",
    "print(df_loaded.head())\n",
    "\n",
    "# 4. 最後の数行\n",
    "print(\"\\n4. 最後の3行:\")\n",
    "print(df_loaded.tail(3))\n",
    "\n",
    "# 5. データ型と欠損値の情報\n",
    "print(\"\\n5. データ型と欠損値の情報:\")\n",
    "print(df_loaded.info())\n",
    "\n",
    "# 6. 統計サマリー\n",
    "print(\"\\n6. 数値列の統計サマリー:\")\n",
    "print(df_loaded.describe())\n",
    "\n",
    "# 7. カテゴリ列のユニーク値\n",
    "print(\"\\n7. カテゴリ列のユニーク値:\")\n",
    "categorical_columns = ['商品名', 'カテゴリ', '地域']\n",
    "for col in categorical_columns:\n",
    "    if col in df_loaded.columns:\n",
    "        print(f\"   {col}: {df_loaded[col].unique()}\")\n",
    "        print(f\"   ユニーク数: {df_loaded[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77d8cb4",
   "metadata": {},
   "source": [
    "## 5. 列・行の抽出とフィルタリング\n",
    "\n",
    "pandasでデータを抽出・フィルタリングする様々な方法を学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== 列の抽出 ===\")\n",
    "\n",
    "# 1. 単一列の抽出\n",
    "print(\"1. 単一列の抽出（商品名）:\")\n",
    "product_names = df_loaded['商品名']\n",
    "print(f\"データ型: {type(product_names)}\")  # Series\n",
    "print(product_names.head())\n",
    "\n",
    "# 2. 複数列の抽出\n",
    "print(\"\\n2. 複数列の抽出（商品名、カテゴリ、売上金額）:\")\n",
    "selected_columns = df_loaded[['商品名', 'カテゴリ', '売上金額']]\n",
    "print(f\"データ型: {type(selected_columns)}\")  # DataFrame\n",
    "print(selected_columns.head())\n",
    "\n",
    "# 3. 条件による列の抽出（数値列のみ）\n",
    "print(\"\\n3. 数値列のみを抽出:\")\n",
    "numeric_columns = df_loaded.select_dtypes(include=[np.number])\n",
    "print(f\"数値列: {list(numeric_columns.columns)}\")\n",
    "print(numeric_columns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc38588",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== 行の抽出・フィルタリング ===\")\n",
    "\n",
    "# 1. インデックスによる行の抽出\n",
    "print(\"1. インデックスによる行の抽出:\")\n",
    "print(\"最初の3行 (iloc[0:3]):\")\n",
    "print(df_loaded.iloc[0:3])\n",
    "\n",
    "print(\"\\n特定の行 (iloc[5]):\")\n",
    "print(df_loaded.iloc[5])\n",
    "\n",
    "# 2. 条件によるフィルタリング\n",
    "print(\"\\n2. 条件によるフィルタリング:\")\n",
    "\n",
    "# 売上金額が5000以上のデータ\n",
    "high_sales = df_loaded[df_loaded['売上金額'] >= 5000]\n",
    "print(f\"売上金額5000以上のデータ: {len(high_sales)}件\")\n",
    "print(high_sales.head())\n",
    "\n",
    "# 特定のカテゴリのデータ\n",
    "electronics = df_loaded[df_loaded['カテゴリ'] == '電子機器']\n",
    "print(f\"\\n電子機器カテゴリのデータ: {len(electronics)}件\")\n",
    "print(electronics.head(3))\n",
    "\n",
    "# 複数条件（AND）\n",
    "high_electronics = df_loaded[\n",
    "    (df_loaded['カテゴリ'] == '電子機器') & \n",
    "    (df_loaded['売上金額'] >= 3000)\n",
    "]\n",
    "print(f\"\\n電子機器かつ売上3000以上: {len(high_electronics)}件\")\n",
    "\n",
    "# 複数条件（OR）\n",
    "high_value = df_loaded[\n",
    "    (df_loaded['売上金額'] >= 8000) | \n",
    "    (df_loaded['数量'] >= 8)\n",
    "]\n",
    "print(f\"\\n売上8000以上または数量8以上: {len(high_value)}件\")\n",
    "\n",
    "# isinを使用した条件\n",
    "target_products = ['商品A', '商品B']\n",
    "selected_products = df_loaded[df_loaded['商品名'].isin(target_products)]\n",
    "print(f\"\\n商品AまたはBのデータ: {len(selected_products)}件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514a7d3",
   "metadata": {},
   "source": [
    "## 6. データの集計（groupby、集約関数）\n",
    "\n",
    "`groupby()`と集約関数を使って、データを分類・集計する方法を学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== データの集計 ===\")\n",
    "\n",
    "# 1. カテゴリ別の基本集計\n",
    "print(\"1. カテゴリ別の売上集計:\")\n",
    "category_sales = df_loaded.groupby('カテゴリ')['売上金額'].agg([\n",
    "    'sum',    # 合計\n",
    "    'mean',   # 平均\n",
    "    'count',  # 件数\n",
    "    'max',    # 最大値\n",
    "    'min'     # 最小値\n",
    "]).round(2)\n",
    "\n",
    "print(category_sales)\n",
    "\n",
    "# 2. 商品別の集計\n",
    "print(\"\\n2. 商品別の売上集計:\")\n",
    "product_sales = df_loaded.groupby('商品名')['売上金額'].sum().sort_values(ascending=False)\n",
    "print(product_sales)\n",
    "\n",
    "# 3. 地域別の集計\n",
    "print(\"\\n3. 地域別の集計:\")\n",
    "region_stats = df_loaded.groupby('地域').agg({\n",
    "    '売上金額': ['sum', 'mean'],\n",
    "    '数量': ['sum', 'mean'],\n",
    "    '商品名': 'count'  # 取引件数\n",
    "}).round(2)\n",
    "\n",
    "print(region_stats)\n",
    "\n",
    "# 4. 複数列でのグループ化\n",
    "print(\"\\n4. カテゴリ×地域別の売上:\")\n",
    "category_region = df_loaded.groupby(['カテゴリ', '地域'])['売上金額'].sum().unstack(fill_value=0)\n",
    "print(category_region)\n",
    "\n",
    "# 5. 集計結果の可視化用データ\n",
    "print(\"\\n5. 集計結果の保存:\")\n",
    "category_summary = df_loaded.groupby('カテゴリ').agg({\n",
    "    '売上金額': 'sum',\n",
    "    '数量': 'sum',\n",
    "    '商品名': 'count'\n",
    "}).round(2)\n",
    "\n",
    "category_summary.columns = ['売上合計', '数量合計', '取引件数']\n",
    "print(category_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f088ebc",
   "metadata": {},
   "source": [
    "## 7. データの並び替えと欠損値処理\n",
    "\n",
    "`sort_values()`による並び替えと、欠損値の確認・処理方法を学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc55f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== データの並び替え ===\")\n",
    "\n",
    "# 1. 単一列による並び替え\n",
    "print(\"1. 売上金額で降順に並び替え:\")\n",
    "sorted_by_sales = df_loaded.sort_values('売上金額', ascending=False)\n",
    "print(sorted_by_sales[['商品名', 'カテゴリ', '売上金額']].head())\n",
    "\n",
    "# 2. 複数列による並び替え\n",
    "print(\"\\n2. カテゴリ→売上金額で並び替え:\")\n",
    "sorted_multi = df_loaded.sort_values(['カテゴリ', '売上金額'], ascending=[True, False])\n",
    "print(sorted_multi[['商品名', 'カテゴリ', '売上金額']].head(10))\n",
    "\n",
    "# 3. インデックスのリセット\n",
    "print(\"\\n3. インデックスをリセット:\")\n",
    "sorted_reset = df_loaded.sort_values('売上金額', ascending=False).reset_index(drop=True)\n",
    "print(sorted_reset[['商品名', 'カテゴリ', '売上金額']].head())\n",
    "\n",
    "print(\"\\n=== 欠損値の確認と処理 ===\")\n",
    "\n",
    "# まず、意図的に欠損値を作成してデモンストレーション\n",
    "df_with_missing = df_loaded.copy()\n",
    "\n",
    "# ランダムに欠損値を作成\n",
    "np.random.seed(42)\n",
    "missing_indices = np.random.choice(df_with_missing.index, size=10, replace=False)\n",
    "df_with_missing.loc[missing_indices, '単価'] = np.nan\n",
    "\n",
    "missing_indices2 = np.random.choice(df_with_missing.index, size=5, replace=False)\n",
    "df_with_missing.loc[missing_indices2, 'カテゴリ'] = np.nan\n",
    "\n",
    "# 1. 欠損値の確認\n",
    "print(\"1. 欠損値の確認:\")\n",
    "print(f\"欠損値の数:\\n{df_with_missing.isnull().sum()}\")\n",
    "print(f\"\\n欠損値の割合:\\n{(df_with_missing.isnull().sum() / len(df_with_missing) * 100).round(2)}%\")\n",
    "\n",
    "# 2. 欠損値のある行を表示\n",
    "print(\"\\n2. 欠損値のある行:\")\n",
    "missing_rows = df_with_missing[df_with_missing.isnull().any(axis=1)]\n",
    "print(f\"欠損値のある行数: {len(missing_rows)}\")\n",
    "print(missing_rows[['商品名', 'カテゴリ', '単価', '売上金額']].head())\n",
    "\n",
    "# 3. 欠損値の処理方法\n",
    "print(\"\\n3. 欠損値の処理:\")\n",
    "\n",
    "# 3.1 欠損値を含む行を削除\n",
    "df_dropped = df_with_missing.dropna()\n",
    "print(f\"欠損値削除後の行数: {len(df_dropped)} (元: {len(df_with_missing)})\")\n",
    "\n",
    "# 3.2 欠損値を平均値で埋める\n",
    "df_filled_mean = df_with_missing.copy()\n",
    "df_filled_mean['単価'] = df_filled_mean['単価'].fillna(df_filled_mean['単価'].mean())\n",
    "print(f\"単価の平均値: {df_filled_mean['単価'].mean():.2f}\")\n",
    "\n",
    "# 3.3 欠損値を最頻値で埋める\n",
    "df_filled_mode = df_with_missing.copy()\n",
    "mode_category = df_filled_mode['カテゴリ'].mode()[0]  # 最頻値\n",
    "df_filled_mode['カテゴリ'] = df_filled_mode['カテゴリ'].fillna(mode_category)\n",
    "print(f\"カテゴリの最頻値: {mode_category}\")\n",
    "\n",
    "print(\"\\n欠損値処理後の確認:\")\n",
    "print(f\"平均値埋め後の欠損値: {df_filled_mean.isnull().sum().sum()}\")\n",
    "print(f\"最頻値埋め後の欠損値: {df_filled_mode.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1573516",
   "metadata": {},
   "source": [
    "## 8. 簡単なグラフ描画\n",
    "\n",
    "pandasの`plot()`メソッドを使って、データを可視化してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f73e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフ描画の準備\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# 1. カテゴリ別売上の棒グラフ\n",
    "plt.subplot(2, 3, 1)\n",
    "category_sales_sum = df_loaded.groupby('カテゴリ')['売上金額'].sum()\n",
    "category_sales_sum.plot(kind='bar', color='skyblue')\n",
    "plt.title('カテゴリ別売上合計')\n",
    "plt.xlabel('カテゴリ')\n",
    "plt.ylabel('売上金額')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 2. 商品別売上の棒グラフ\n",
    "plt.subplot(2, 3, 2)\n",
    "product_sales_sum = df_loaded.groupby('商品名')['売上金額'].sum()\n",
    "product_sales_sum.plot(kind='bar', color='lightgreen')\n",
    "plt.title('商品別売上合計')\n",
    "plt.xlabel('商品名')\n",
    "plt.ylabel('売上金額')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 3. 地域別売上の円グラフ\n",
    "plt.subplot(2, 3, 3)\n",
    "region_sales = df_loaded.groupby('地域')['売上金額'].sum()\n",
    "region_sales.plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "plt.title('地域別売上構成比')\n",
    "plt.ylabel('')\n",
    "\n",
    "# 4. 売上金額のヒストグラム\n",
    "plt.subplot(2, 3, 4)\n",
    "df_loaded['売上金額'].hist(bins=20, alpha=0.7, color='orange')\n",
    "plt.title('売上金額の分布')\n",
    "plt.xlabel('売上金額')\n",
    "plt.ylabel('頻度')\n",
    "\n",
    "# 5. 単価と数量の散布図\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.scatter(df_loaded['単価'], df_loaded['数量'], alpha=0.6, color='red')\n",
    "plt.title('単価と数量の関係')\n",
    "plt.xlabel('単価')\n",
    "plt.ylabel('数量')\n",
    "\n",
    "# 6. 日付別売上の折れ線グラフ\n",
    "plt.subplot(2, 3, 6)\n",
    "daily_sales = df_loaded.groupby('日付')['売上金額'].sum().sort_index()\n",
    "daily_sales.plot(kind='line', marker='o', linewidth=2, markersize=4)\n",
    "plt.title('日別売上推移')\n",
    "plt.xlabel('日付')\n",
    "plt.ylabel('売上金額')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"グラフを表示しました！\")\n",
    "\n",
    "# 個別のグラフも作成してみる\n",
    "print(\"\\n=== 追加のグラフ分析 ===\")\n",
    "\n",
    "# カテゴリ別の詳細分析\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 左：カテゴリ別平均売上\n",
    "category_avg = df_loaded.groupby('カテゴリ')['売上金額'].mean()\n",
    "category_avg.plot(kind='bar', ax=axes[0], color='purple', alpha=0.7)\n",
    "axes[0].set_title('カテゴリ別平均売上')\n",
    "axes[0].set_xlabel('カテゴリ')\n",
    "axes[0].set_ylabel('平均売上金額')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 右：カテゴリ別取引件数\n",
    "category_count = df_loaded.groupby('カテゴリ').size()\n",
    "category_count.plot(kind='bar', ax=axes[1], color='brown', alpha=0.7)\n",
    "axes[1].set_title('カテゴリ別取引件数')\n",
    "axes[1].set_xlabel('カテゴリ')\n",
    "axes[1].set_ylabel('取引件数')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 基本統計の確認\n",
    "print(\"\\n=== 最終的な分析サマリー ===\")\n",
    "print(f\"総取引件数: {len(df_loaded):,}件\")\n",
    "print(f\"総売上金額: {df_loaded['売上金額'].sum():,.0f}円\")\n",
    "print(f\"平均売上金額: {df_loaded['売上金額'].mean():.0f}円\")\n",
    "print(f\"最高売上: {df_loaded['売上金額'].max():,.0f}円\")\n",
    "print(f\"最低売上: {df_loaded['売上金額'].min():,.0f}円\")\n",
    "\n",
    "print(\"\\nカテゴリ別売上ランキング:\")\n",
    "category_ranking = df_loaded.groupby('カテゴリ')['売上金額'].sum().sort_values(ascending=False)\n",
    "for i, (category, sales) in enumerate(category_ranking.items(), 1):\n",
    "    print(f\"{i}位: {category} - {sales:,.0f}円\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c123131",
   "metadata": {},
   "source": [
    "## 学習完了！🎉\n",
    "\n",
    "お疲れ様でした！このノートブックでpandasの基本的なデータ操作・分析手法を学習しました。\n",
    "\n",
    "### 習得したスキル\n",
    "1. ✅ **pandasの基本設定とライブラリインポート**\n",
    "2. ✅ **DataFrameの作成とデータ構造の理解**\n",
    "3. ✅ **CSVファイルからのデータ読み込み**\n",
    "4. ✅ **データの基本情報確認**（shape, head, info, describe）\n",
    "5. ✅ **列・行の抽出とフィルタリング**\n",
    "6. ✅ **groupbyを使ったデータ集計**\n",
    "7. ✅ **データの並び替えと欠損値処理**\n",
    "8. ✅ **pandasのplotメソッドによる可視化**\n",
    "\n",
    "### 次のステップ\n",
    "これらの基本スキルを身につけたので、次は以下のような発展的な内容に進むことができます：\n",
    "\n",
    "1. **より高度なデータ分析**\n",
    "   - 時系列データの分析\n",
    "   - 顧客セグメンテーション\n",
    "   - 売上予測\n",
    "\n",
    "2. **外部データソースとの連携**\n",
    "   - APIからのデータ取得\n",
    "   - データベースとの連携\n",
    "   - Webスクレイピングとの組み合わせ\n",
    "\n",
    "3. **高度な可視化**\n",
    "   - Seabornを使った統計的可視化\n",
    "   - インタラクティブな可視化（Plotly）\n",
    "   - ダッシュボードの作成\n",
    "\n",
    "### 実践的な演習課題\n",
    "1. 自分の興味のあるデータセット（Kaggleなど）をダウンロードして分析してみる\n",
    "2. 複数のCSVファイルを結合して統合分析を行う\n",
    "3. 時系列データで移動平均やトレンド分析を実装する\n",
    "\n",
    "**素晴らしい学習でした！引き続きpandasを使ったデータ分析を楽しんでください！** 📊✨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
